# Gradus ad IO Parnassum
Author Marek Scholle <marekscholle@gmail.com>
v0.1, 2021-06-26
:source-highlighter: highlightjs
:highlightjs-languages: scala, shell
:sectanchors:
:icons: font
:toc: left
:sectnums:
:toclevels: 4
:docinfo: shared
:!webfonts:
:stem: latexmath

This is my attempt to introduce IO monad programming for those
who never heard aboutÂ it.
Unlike material I myself found when IÂ first met the concept,
this does not try to "`sell`" it from the beginning
as purely functional, referentially transparent solution,
but rather as aÂ smart way to organize computation,
to get concurrent execution of subprograms virtually for free
and without magic, and to avoid stack overflows.

The language I choose for presenting ideas is
https://www.scala-lang.org[Scala 3], which is one of JVM languages.
IÂ intentionally avoid using advanced Scala feautures and syntax sugar
(like
https://docs.scala-lang.org/tour/for-comprehensions.html[for comprehension]
or https://docs.scala-lang.org/tour/by-name-parameters.html[by-name parameters]),
so that even aÂ reader without prior knowledge will understand.

## Prerequsities

It is supposed that aÂ reader already knows basics of generic Java-like
OOP typed programming
(classes, instances, functions, generics) and the term _interface_
as prescription of functionality which must be implemented
by type implementing the interface.
Classic example:

[source, scala]
----
trait Animal:
  def name: String
  def makeSound: String
  def introduceSelf(): Unit =
    println(s"Hi! I'm $name and I do '$makeSound'!")
----

NOTE: https://docs.scala-lang.org/tour/traits.html[Traits] are
similar to Java interfaces.
Returning `Unit` is a Scala's way of saying "`return nothing`",
like `void` inÂ C++ or Java. The `Unit` is the 0-tuple type,
and its only instance has a special (natural) notation: `()`.
I some sense it is an equavilent of Python's `None` â€“
if you specify that aÂ function returns `Unit`,
you don't need to return `()` explicitely,
it is returned automatically.

Any (concrete) type implementing `Animal` trait has to implement
methods `name` and `makeSound`, and the method `introduceSelf`
is (by default) implemented in terms of these two methods.
One way to get an instance of `Animal` is to define _anonymous_
implementation:

[source, scala]
----
val bob = new Animal:
  def name: String = "Bob"
  def makeSound: String = "Woof"
----

If we run `bob.introduceSelf()`, we will get `Hi! I'm Bob and I do 'Woof'!`
inÂ the console.

As this runs in JVM, we mostly don't care about object lifecycles;
as long as we can reach anÂ object (through chain of references)
it lives on the heap.

### Sealed traits

In the text we will use one convenience of Scala language: _sealed traits_.
Marking an interface as _sealed_ tells the compiler there will be no other
implementations than those provided in the same file:

[source, scala]
----
/** Skeleton of naive implementation of generic `Option` type with
  * two variants: empty ([[None]]) and present ([[Some]]).
  * No one outside the file can extend `Option[A]`.
  */
sealed trait Option[A]
  def get: A
  def map(f: A => B): Option[B]

object Option:
  case class None[A]() extends Option[A]
    def get: A = throw NoSuchElementException
    def map(f: A => B): None[B] = None()

  case class Some[A](value: A) extends Option[A]
    def get: A = value
    def map(f: A => B): Some[B] = Some(f(value))
----

The benefit is that if we have an instance `opt` of type `Option[A]`,
the compiler knows what are all possible variants and provides us a way to
do complete _pattern matching_ on the instance:

[source, scala]
----
opt match
  case Some(value) => // handle the "present" case
  case None        => // handle the "empty" case
----

### Tail recursion

If you don't know what it is, let's start with aÂ simple recursive function
which sums integers from 1Â toÂ `n`:

[source, scala]
----
def sum(n: Int): Int =
  assert(n >= 0)
  if (n == 0) 0
  else n + sum(n - 1)
----

If we run `sum(1_000_000)` we get stack overflow â€“
when executing `sum` for anÂ `n > 0`,
the compiler must first create aÂ stack frame to compute
`sum(nÂ -Â 1)` and _only then_ it can addÂ `n` and return.
The  important thing here is that there is aÂ work to do
_after_ the recursive call.

On the contrary, the program

[source, scala]
----
def helloWorldForever(): Nothing
  println("Hello, world")
  helloWorldForever()
----

will (in Scala) not cause stack overflow: the compiler is smart
enough to see that it can _reuse_ the stack frame for `helloWorldForever`
for another call of it.

Scala has aÂ special annotation for checking that aÂ recursive function
boiles down to aÂ tail-recursive one: `@tailrec`.
If we apply this annotation to our `sum` example,
we get aÂ compilation error:

[source, text]
----
@tailrec def sum(n: Int): Int =
  if (n == 0) 0
  else (n + sum(n - 1))
          ^
error: could not optimize @tailrec annotated method sum: it contains
a recursive call not in tail position
----

Tail-recursion is good: it is cheaper than the usual one
and we don't risk stack overflows.
It is a viable replacement for imperative loops:

[source, scala]
----
def imperativeSum(n: Int) =
  var acc = 0
  (1 to n).forEach { i => acc += i }
  acc
----

is better written (without any mutation)

[source, scala]
----
def sum(n: Int) =
  @tailrec
  def loop(n: Int, acc: Int) =
    if (n == 0) acc
    else loop(n - 1, n + acc)
  loop(n, 0)
----

The trick to turn anÂ imperative loop to `@tailrec` recursion
by making local mutable variable aÂ helper `@tailrec` function parameter
is not uncommon, but requires some practise.


## Gradus ad `Program`

We start with a question how we can represent aÂ _program_ in our code.
This may raise questions

* Why we would do that?
* What's wrong with writing of program starting from main function
and calling other functions?
* What's the difference between aÂ function (like the main one) and
your  "`program`"?

Of course, there is nothing wrong with code starting from main function
and calling other functions.
But as we will see, formulating what is a "`program`" will provide us
some non-trivial benefits; it will provide us aÂ way to _implement_ some
concepts that usually must be provided by language itself
(and often are not).

### Step No. 1

Our first attempt to represent an executable piece of code may look like this:

[source, scala]
----
trait Program1:
  def execute(): Unit
----

`Program1` is aÂ minimalÂ version of _program_ which does not take any arguments
and returns nothing.
It is the same as Java's
https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Runnable.html[
`Runnable`],
people coming fromÂ C background would maybe call this aÂ _callback_ type
as this type is aÂ natural candidate for callbacks fired when something happens.

As it does return nothing, it is not much useful.
The only thing we can do is aÂ primitive chain operation:

[source, scala]
----
trait Program1:
  def execute(): Unit // abstract

  /** Program which first executes `this` program
    * and then the `that` program.
    */
  def andThen(that: Program1): Program1 =
    val self = this
    new Program1:
      def execute(): Unit =
        self.execute()
        that.execute()
----

So, given two programsÂ `p` andÂ `q`, we can easily create aÂ program which
sequentially executes both: `p.andThen(q)`. We can pass anÂ instance of
`Program1` as argument to some function which may (and may not)
execute the piece of code suspended in `execute` method.
(This what you do in Java when you pass aÂ `Runnable` instance
to `Thread` constructor.)

It is worth noting that the requirement that `Program1` does not
accept any arguments does not limit us: we can capture ("`bake`")
whatever we want into an instance of `Program1` like this:

[source, scala]
----
val a = 1
val b = 2
val program = new Program1:
  def execute(): Unit =
    // the references to `a` and `b` are captured into this
    // anonymous `Program1`'s state, so we can refer to them
    // as if with `this.a` and `this.b`
    println(s"$a + $b = ${a + b}")
----

It is generally useful to ask what is aÂ minimal example of interfaces
we meet: for aÂ set, it would be an empty set, for `Program1`, it is
aÂ program which accepts nothing, does nothing and returns nothing
(which means compiler will rewrite it to return `()`):

[source, scala]
----
val doNothing = new Program1:
  def execute(): Unit = {}
----

### Step No. 2

The (obvious) problem is that we `execute` aÂ `Program1` just
for its _side effect(s)_: sure, we can print its result to console,
to file, to database, or to save it to some agreed-before piece of memory,
but of course this is clumsy.
The natural thing to do is to make the program generic in its _return type_:

[source, scala]
----
trait Program2[A]:
  def execute(): A
----

This is much better.
As before, we don't need `Program2` to accept arguments for `execute` method
as we can bake whatever we need directly into instance of `Program2`.
The difference is that the execution of program now has means
to return its result without modifying external world.
Please note that `Program2` is aÂ direct generalization of `Program1`
which is the same as `Program2[Unit]`.

Let's examine what we can do with `Program2`.
As we now have a meaningful result of execution,
we can create aÂ new program by remaping the result of another one:

[source, scala]
----
trait Program2[A]:
  def execute(): A // abstract

  /** Program which executes `this` program, passes the result
    * as argument to `f` and returns its result.
    */
  def map[B](f: A => B): Program2[B] =
    val self = this
    new Program2[B]:
      def execute(): B =
        val a = self.execute()
        f(a)
----

Hence, given aÂ function `f: A \=> B`, we can easily transform
aÂ `Program2[A]` to `Program2[B]`
by applying `f` on the result of the former one.
(Note that `Program2[A].map[B]` only schedules this operation for execution
when the resulting program is executed, it does not call it itself.)
In other words (more elaborately), `map` is anÂ operation which takes
aÂ `Program2[A]` (implicit `this`), aÂ function `A \=> B` and returns
`Program2[B]`.

So far we have not done anything surprising or unclear:
we just have crafted an interface (`Program2`) to wrap
aÂ function (`execute`) with baken-into arguments,
with convenient syntax to apply aÂ transformation on the result (`map`).
Now we will introduce first non-obvious thing:
if we substitute `BÂ === Program[C]` in `map[B](f: A \=> B)`,
we meet aÂ type for aÂ _program producing another program_
since the return type of `map(f: A \=> Program[C])` is `Program[Program[C]]`.

Not suprisingly, `Program[Program[C]]` belongs
to "`family`" of programs producing a `C`.

NOTE: If you know `Future[A]` (or `Promise<A>` in Javascript),
an analogy is at hand: `Future[A]` is aÂ "`container for future value`",
or aÂ "`value that will be known in some point in the future`".
The type `Future[Future[A]]` thus represents aÂ "`future value in some point
in the future`", which is still aÂ value in future (with some known
intermediate step).

The proof of this claim is aÂ function which takes aÂ `Program2[Program2[A]]`
and returns aÂ `Program2[A]`; aÂ function of "`shape`" `F[F[A]]Â \=>Â F[A]`
is usually called `flatten`.
The implementation is trivial and is in fact the _only possible_ implementation:

[source, scala]
----
// free-standing function, not part of `trait Program2[A]`
def flatten(program: Program2[Program2[A]]): Program2[A] =
  new Program2[A]:
    def execute(): A =
      program.execute().execute()
----

In words: to produce anÂ `A` from `Program2[Program2[A]]`,
we must execute the outer `Program2` to get (inner)Â `Program2[A]`
which we then execute to get wanted `A`.

It is now only anÂ intelectual curiosity to produce aÂ program producing
program, but soon we will see how useful this is. Usually we don't
write `flatten(program.map(f))`, where `program` is aÂ `Program2[A]`
and `f` is anÂ `A \=> Program[B]`, but use map and flatten in aÂ single
step called `flatMap`:

[source, scala]
----
trait Program2[A]:
  def execute(): A

  /** Program which first executes `this` program and passes the result
    * as argument to `f` to obtain another program which is then executed
    * and its result returned.
    */
  def flatMap[B](f: A => Program2[B]): Program2[B] =
    val self = this
    new Program2[B]:
      def execute(): B =
        val a = self.execute()
        f(a).execute()
----

Please note this is in fact _the_Â direct transformation of `andThen` from
`Program1` (with regard to generalization of `Program1` to `Program2[A]`):
just with `Program2[A]` we can use the result of the first
program to _create_ the second one; in other words, "`bake`" the result
of the first program into the second one as additional argument
(known only after first program has been executed and its result is known).

As with `Program1`, it is good to ask what is theÂ minimal
implementation of `Program2[A]`. It is theÂ program which just returns
aÂ value which we already know (again, `ready[Unit]` is equavalent to
``Program1``'s `doNothing`):

[source, scala]
----
def ready[A](a: A): Program2[A] =
  new Program2[A]:
    def execute(): A = a
----

Now it is worth noting that when we have `flatMap` operation
and the `ready` factory,
we implement `map` operation in terms of these two:
the equivalence is

[source, scala]
----
program.map(f) === program.flatMap { x => ready(f(x)) }
----

(Please reread the contracts of `map`, `flatMap` and `ready` to confirm
this is not aÂ lie.)
IÂ intentionally use the term _equivalence_ to avoid confusion with _equality_,
the left hand and right hand expressions represent the same logical programs,
but are not equal as object instances.

#### Example

Let us write aÂ simple program using our `Program2`.
As anÂ example we take aÂ well known recursive
problem
(https://en.wikipedia.org/wiki/Collatz_conjecture[Collatz conjecture])
which goes this way: given aÂ positive numberÂ `n`,
if it is odd, mutliply it byÂ 3 and addÂ 1
(hence the name _`3nÂ +Â 1` problem_) and repeat,
if it is even, divide byÂ 2 and repeat.
The Collatz conjecture states that for every startingÂ `n`,
you will eventually reach the cycle 1,Â 2,Â 4.
Let's implement aÂ program which, for given `n`,
computes the number of steps until the sequence reachesÂ 1.
(Example: for `n`Â =Â 6, the sequence is 3,Â 10, 5, 16, 8, 4, 2,Â 1
and hence the result isÂ 8).

[source, scala]
----
def collatz(n: BigInt): Program2[BigInt] =
  new Program2[BigInt]:
    def execute(): BigInt =
      if (n == 1) 0
      else
        val c =
          if (n % 2 == 0) collatz(n / 2)
          else collatz(3 * n + 1)
        c.map(_ + 1).execute()
----

To check the result of this program, let's introduce another program
for printing a labeled value:

[source, scala]
----
def print[A](label: String, a: A): Program2[Unit] =
  new Program2[Unit]:
    def execute(): Unit =
      println(s"$label: $a")
----

The program which, for givenÂ `n`, computes the lenght of
`3n + 1` sequence and prints its length, is

[source, scala]
----
def collatzAndPrint(n: BigInt): Program2[Unit] =
  collatz(n).flatMap { len => print(s"length($n)", len) }
----

When we `execute` the program `collatzAndPrint(8)`,
we will see `length(6): 8` as expected.
As you can observe (or verify),
this implementation extensively uses stack
(you would need to find a very largeÂ `n` to overflow the stack though).
Moreover, the implementation is hardly in any sense better than plain

[source, scala]
----
def collatz(n: BigInt): BigInt =
  if (n == 1) 0
  else
    val c =
      if (n % 2 == 0) collatz(n / 2)
      else collatz(3 * n + 1)
    c + 1
----

### Step No. 3

Let summarize what we have in single listing.
(We delegate `flatMap` to aÂ free-standing function in companion object
which acts as namespace so that `ready` and `flatMap` are both
free-standing functions.)
The `map` operation is implemented in terms
of `ready` and `flatMap`; it is not treated as "`aÂ primitive`" operation.

[source, scala]
----
trait Program3[A]:
  def execute(): A

  def map[B](f: A => B): Program3[B] =
    flatMap { a => Program3.ready(a) }

  def flatMap[B](f: A => Program3[B]): Program3[B] =
    Program3.flatMap(this, f)

object Program3:
  def ready[A](a: A): Program3[A] =
    new Program3[A]:
      def execute(): A = a

  def flatMap[A, B](
      program: Program3[A],
      f: A => Program3[B],
  ): Program3[B] =
    new Program3[B]:
      def execute(): B =
        f(program.execute()).execute()

  def flatten[A](program: Program2[Program2[A]]): Program2[A] =
    // `identity` is the generic identity function function x |-> x
    program2.flatMap(identity)
----

We already have much than one might expect,
but the question if it is useful is still not answered.
The basic problem is that we force `Program3` to provide `execute`
method, and once we call it,
the program has no option but to do everything it can to produce
the output, blocking the thread and growing the stack during its execution.
It is nothing more than just aÂ funny form of normal functions,
we only bake arguments into instances of `Program2` (usually anonymous)
and name the function call as `execute`.

To see benefits of such programs, we must do oneÂ non-obvious step
(maybe surprising for those from OOP world):
remove the `execute` method from the interface and thus _relieve_ programs
from the concern of their _execution_.
Note we started with `Program1` which had nothing but `execute`,
and now we remove this `execute` from the interface and
are finding something which will drive programs execution:
the _interpreter_.
(IÂ used the term _interpreter_ to avoid confusion
with threading task scheduling mechanisms called _executors_.)

### Step No. 4

So we remove `execute` from `Program3` and get

[source, scala]
----
sealed trait Program[A]:
  def map[B](f: A => B): Program[B] =
    flatMap { a => Program.ready(a) }
  def flatMap[B](f: A => Program[B]): Program[B] =
    Program.FlatMap(this, f)

object Program:
  /** Program which returns an already existing value. */
  private case class Ready[A](a: A) extends Program[A]

  /** Program which (when interpreted) executes the `program`,
    * applies `f` on its result to get an another program, runs it
    * and returns its result.
    */
  private case class FlatMap[A, B](
      program: Program[A],
      f: A => Program[B],
  ) extends Program[B]
----

Note that we now don't have anything to do in `flatMap`
implementation, so we just _save_ the parameters to aÂ (named) case
ofÂ `Program[A]` in the hope that something (interpreter)
will use it when executing the program.
IÂ use `private` for the cases to denote that aÂ client shall
use factories to create ``Program``s, and not refer to
concrete implementations directly.

As before, we have the minimal implementation of `Program[A]`:

[source, scala]
----
def ready[A](a: A): Program[A] = Ready(a)
----

With what we already have, let's prepare two other factories for ``Program``s:

[source, scala]
----
def suspend[A](f: () => A): Program[A] =
  ready(()).map(f)
----

This factory _suspends_ the supplied function into a `Program[A]`,
when the program is executed (by interpreter),
the result of the suspended function is used as the result of the program.

[source, scala]
----
def defer[A](f: () => Program[A]): Program[A] =
  ready(()).flatMap(f)
----

This factory suspends the supplied function which produces a program.
When the the result of `defer` is executed (by interpreter), we first
run the functionÂ `f` to obtain aÂ program which is executed next
toÂ obtain the program result.

Please note that no one requires (and has any means to force) that
parameters of `map` and `flatMap` do not do any side effects,
on the contrary it very common (especially in `flatMap` or `defer`)
to do them.

### Naive interpreter for `Program`

Let's write _some_ interpreter for `Program[A]` just to prove that
by removing `execute` from `Program` interface we lose nothing:

[source, scala]
----
def run1[A](program: Program[A]): A =
  program match
    case Ready(a) =>
      a

    case FlatMap(program1, f) =>
      val a1 = run1(program1) // not a tail call
      val program2 = f(a1)
      run1(program1)
----

Note this is aÂ trivial straightforward implementation,
driven by types. You can't do anything else with aÂ `Program`
passed as argument than pattern-match it.
If it is aÂ `Ready[A](a)`, the situation is trivial.
If it is aÂ `FlatMap[B, A](program1, f)` for some typeÂ `B`,
aÂ natural thing to do is to execute `program1: Program2[B]` to get aÂ `B`,
applyÂ `f` to get `program2: Program2[A]` and execute it to getÂ `A`.

Let's test our Collatz program against this interpreter:

[source, scala]
----
def collatz(n: BigInt): Program[BigInt] =
  Program.defer { () =>
    if (n == 1) Program.ready(0)
    else {
      if (n % 2 == 0) collatz(n / 2).map(_ + 1)
      else collatz(3 * n + 1).map(_ + 1)
    }
  }

def printResult(n: BigInt) = suspend { () =>
  println(s"Result: $n")
}

run1(collatz(6).flatMap(printResult))
----

outputs:

----
Result: 8
----

If you inspect stack usage, you will see that execution of `collatz(6)`
by `run1` needs about 10 stack frames.
The reason is that during recursion we build aÂ chain of ``Map``s:
the `collatz(n)` gradually builds (from right) aÂ program
`ready(0).map(_ + 1)[\...].map(_ + 1)` which execution consumes a stack.
Let's fix that.

### Tail-recursive rewrite of naive interpreter

It needs some experience to rewrite stack-consuming
recursion to aÂ tail-recursive one.
IÂ applied my experience to `run1` and admittedly, this was aÂ quite hard nut.
IÂ finally and ended up with

[source, scala]
----
sealed trait Todo[B]
object Todo:
  case class Done[B](b: B) extends Todo[B]
  case class More[A, B](
      program: Program[A],
      todo: A => Todo[B],
  ) extends Todo[B]

@tailrec
def loop2[A, B](program: Program[A], todo: A => Todo[B]): B =
  import Todo._
  program match {
    case Ready(a) =>
      todo(a) match {
        case Done(b)             => b
        case More(program, todo) => loop2(program, todo)
      }

    case FlatMap(program, f) =>
      loop2(
        program,
        x => More(f(x), todo),
      )
  }

def run2[A](program: Program[A]): A =
  loop2(program, a => Todo.Done(a))
----

As it is usual, we delegate the implementation of function we want
to make tail-recursive to aÂ helper tail-recursive helper, here called
`loop2`.
(Note the `@tailrec` annotation which is here to make sure compiler
will use tail call elimination.)
The `todo` parameter is anÂ accumulator of work "`to be done`".
If we run our `collatz(n)` program against `run2` (with some debug logging),
we will see that tail calls are really eliminated.
Using `Program` with `run2` prevents stack overflows ðŸŽ‰,
so already we can get something non-trivial for free.

Not so fast. We just moved to heap what previously was on stack,
the problem with chained ``Map``s is not solved, only we can execute
the problem without overflowing the stack.

#### Example: compute parity of length of list

We have a singly linked list, let's write aÂ program which computes
if its length is odd or even. AÂ naive function version of this would be

[source, scala]
----
/** Returns true if the `list` length is even. */
def even[A](list: List[A]): Boolean =
  list match
    case head :: tail => odd(tail)
    case Nil          => true

/** Returns true if the `list` length is odd. */
def odd[A](list: List[A]): Boolean =
  list match
    case head :: tail => even(tail)
    case Nil          => false

// use it
val list: List[Int] = ???
val hasEvenLength = even(list)
----

For larger lists, this will overflow the stack.
`Program` version will not as the control is always passed back
to interpreter before advancing to next step:

[source, scala]
----
/** Returns true if the `list` length is even. */
def even[A](list: List[A]): Program[Boolean] = defer { () =>
  list match
    case head :: tail => odd(tail)
    case Nil          => true
}

/** Returns true if the `list` length is odd. */
def odd[A](list: List[A]): Program[Boolean] = defer { =>
  list match
    case head :: tail => even(tail)
    case Nil          => false
}

// use it
val list: List[Int] = ???
val hasEvenLength = run2(even(list))
----

The trick of not calling next step directly, but rather returning
aÂ description what is to be done next is called _trampolining_,
and that's what our `run2` does. By representing the term _program_
in code, we are aÂ bit in the role of the programming language designer
or compiler implementor.

### Interpreter of `Program`

I hope it is clear how `run2` implements aÂ tail-recursive interpreter
of ``Program``s with the help of `Todo` variants `Done` and `More`.
But if we look more closely, there is aÂ striking resemblance:
`Done` is like `Ready` and `More` is like `FlatMap`!
So we can rewrite `run2` to

[source, scala]
----
@tailrec
def run[A](program: Program[A]): A =
  program match {
    case Ready(a) =>
      a

    case FlatMap(program, f) =>
      program match
        case Ready(a) =>
          run(f(a))

        case FlatMap(program, g) =>
          run(FlatMap(program, a => FlatMap(g(a), f)))
  }
----

We could write this directly, but it might feel magic
which is something IÂ wanted to avoid.
AÂ bit of additional explanation:
In `case FlatMap`, we inline former `loop2` into the case body,
so pattern match on inner ``FlatMap``'s program.
If the inner program is again aÂ `FlatMap`, we move the function
"`to the right`", removing one "`onion peel`" from the left, so that
we can continue with execution with smaller program: the equavality
here is

[source, scala]
----
FlatMap[B, A](
  FlatMap[C, B](
    program, // Program[C]
    g, // C => Program[B]
  ),
  f, // B => Program[A]
)
  ===
  FlatMap[C, A](
    program, // Program[C]
    h: (c: C) => FlatMap(
      g(c), // Program[B]
      f, // B => Program[A]
    ),
  )
----

or written in dot-notation

[source, scala]
----
// where
val program: Program[C] = ???
val g: C => Program[B] = ???
val f: B => Program[A] = ???
// equivalence
program.flatMap { c => g(c) }.flatMap { b => f(b) }
  === program.flatMap { c => g(c).flatMap { b => f(b) } }
----

This is sometimes called the _associativy (monad) law_ since we can
symbolically write equivalence

[source, scala]
----
[p >>= (c -> g(c))] >>= (b -> f(b)) === p >>= [c -> (g(c) >>= (b -> f(b)))]
----

where `>>=` stands for `flatMap`.